#!/usr/bin/env python3
"""
Telemetry Data Analysis Script

Analyzes telemetry data generated by the IoT simulator for insights and patterns.
"""

import json
import logging
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
except ImportError as e:
    print(f"Required package not installed: {e}")
    print("Please install with: pip install pandas matplotlib seaborn numpy")
    sys.exit(1)


class TelemetryAnalyzer:
    """Analyze telemetry data from IoT simulator."""
    
    def __init__(self, data_source=None):
        self.data_source = data_source
        self.df = None
        self.logger = logging.getLogger('TelemetryAnalyzer')
        
        # Setup plotting style
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
    
    def load_data_from_file(self, file_path: str) -> pd.DataFrame:
        """Load telemetry data from JSON file."""
        try:
            with open(file_path, 'r') as f:
                data = []
                for line in f:
                    try:
                        record = json.loads(line.strip())
                        data.append(record)
                    except json.JSONDecodeError:
                        continue
            
            if not data:
                self.logger.warning(f"No valid JSON records found in {file_path}")
                return pd.DataFrame()
            
            df = pd.DataFrame(data)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            return df
        
        except Exception as e:
            self.logger.error(f"Error loading data from {file_path}: {e}")
            return pd.DataFrame()
    
    def generate_sample_data(self, num_devices=5, hours=24, interval_minutes=1) -> pd.DataFrame:
        """Generate sample telemetry data for analysis."""
        from faker import Faker
        fake = Faker()
        
        # Generate time series
        start_time = datetime.now() - timedelta(hours=hours)
        timestamps = pd.date_range(
            start=start_time,
            end=datetime.now(),
            freq=f'{interval_minutes}min'
        )
        
        data = []
        device_ids = [fake.uuid4() for _ in range(num_devices)]
        farm_ids = [fake.uuid4() for _ in range(2)]  # 2 farms
        room_ids = [fake.uuid4() for _ in range(4)]  # 4 rooms
        
        for timestamp in timestamps:
            for i, device_id in enumerate(device_ids):
                # Simulate realistic sensor data with patterns
                hour = timestamp.hour
                
                # Temperature varies with time of day
                base_temp = 22 + 3 * np.sin(2 * np.pi * hour / 24)
                temperature = base_temp + np.random.normal(0, 0.5)
                
                # Humidity inversely related to temperature
                humidity = 90 - (temperature - 20) * 2 + np.random.normal(0, 2)
                humidity = max(70, min(95, humidity))
                
                # CO2 varies throughout the day
                co2 = 1200 + 200 * np.sin(2 * np.pi * (hour + 6) / 24) + np.random.normal(0, 50)
                
                # Light follows day/night cycle
                if 6 <= hour <= 18:  # Daytime
                    light = 200 + 100 * np.sin(2 * np.pi * (hour - 6) / 12) + np.random.normal(0, 20)
                else:  # Nighttime
                    light = 10 + np.random.normal(0, 5)
                light = max(0, light)
                
                # Battery slowly decreases
                battery = 4.2 - 0.5 * (len(data) / len(device_ids) / len(timestamps)) + np.random.normal(0, 0.1)
                battery = max(3.0, min(4.2, battery))
                
                record = {
                    'device_id': device_id,
                    'farm_id': farm_ids[i % len(farm_ids)],
                    'room_id': room_ids[i % len(room_ids)],
                    'timestamp': timestamp,
                    'temperature_c': round(temperature, 2),
                    'humidity_pct': round(humidity, 2),
                    'co2_ppm': round(co2),
                    'light_lux': round(light, 1),
                    'battery_v': round(battery, 2),
                    'status': 'online'
                }
                
                data.append(record)
        
        return pd.DataFrame(data)
    
    def load_data(self, source=None):
        """Load data from various sources."""
        if source:
            self.data_source = source
        
        if not self.data_source:
            self.logger.info("No data source specified, generating sample data...")
            self.df = self.generate_sample_data()
        elif os.path.isfile(self.data_source):
            self.logger.info(f"Loading data from file: {self.data_source}")
            self.df = self.load_data_from_file(self.data_source)
        else:
            self.logger.info("Generating sample data for demonstration...")
            self.df = self.generate_sample_data()
        
        if self.df.empty:
            raise ValueError("No data available for analysis")
        
        self.logger.info(f"Loaded {len(self.df)} records from {self.df['device_id'].nunique()} devices")
    
    def basic_statistics(self):
        """Generate basic statistics about the data."""
        if self.df is None or self.df.empty:
            print("No data available for analysis")
            return
        
        print("\n" + "="*60)
        print("BASIC STATISTICS")
        print("="*60)
        
        # Data overview
        print(f"Total records: {len(self.df):,}")
        print(f"Unique devices: {self.df['device_id'].nunique()}")
        print(f"Unique farms: {self.df['farm_id'].nunique()}")
        print(f"Unique rooms: {self.df['room_id'].nunique()}")
        
        # Time range
        time_range = self.df['timestamp'].max() - self.df['timestamp'].min()
        print(f"Time range: {time_range}")
        print(f"From: {self.df['timestamp'].min()}")
        print(f"To: {self.df['timestamp'].max()}")
        
        # Sensor statistics
        numeric_columns = ['temperature_c', 'humidity_pct', 'co2_ppm', 'light_lux', 'battery_v']
        available_columns = [col for col in numeric_columns if col in self.df.columns]
        
        if available_columns:
            print("\nSensor Data Statistics:")
            stats = self.df[available_columns].describe()
            print(stats.round(2))
        
        # Device status
        if 'status' in self.df.columns:
            print("\nDevice Status Distribution:")
            status_counts = self.df['status'].value_counts()
            for status, count in status_counts.items():
                percentage = (count / len(self.df)) * 100
                print(f"  {status}: {count:,} ({percentage:.1f}%)")
    
    def plot_time_series(self, save_path=None):
        """Plot time series data for all sensors."""
        if self.df is None or self.df.empty:
            print("No data available for plotting")
            return
        
        numeric_columns = ['temperature_c', 'humidity_pct', 'co2_ppm', 'light_lux', 'battery_v']
        available_columns = [col for col in numeric_columns if col in self.df.columns]
        
        if not available_columns:
            print("No numeric sensor data available for plotting")
            return
        
        fig, axes = plt.subplots(len(available_columns), 1, figsize=(12, 3*len(available_columns)))
        if len(available_columns) == 1:
            axes = [axes]
        
        for i, column in enumerate(available_columns):
            # Plot data for each device
            for device_id in self.df['device_id'].unique():
                device_data = self.df[self.df['device_id'] == device_id]
                axes[i].plot(device_data['timestamp'], device_data[column], 
                           alpha=0.7, label=f'Device {device_id[:8]}...')
            
            axes[i].set_title(f'{column.replace("_", " ").title()}')
            axes[i].set_ylabel(self.get_unit(column))
            axes[i].grid(True, alpha=0.3)
            
            # Only show legend for first few devices to avoid clutter
            if self.df['device_id'].nunique() <= 5:
                axes[i].legend()
        
        plt.xlabel('Time')
        plt.tight_layout()
        plt.suptitle('Sensor Data Time Series', y=1.02, fontsize=16)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Time series plot saved to: {save_path}")
        else:
            plt.show()
    
    def plot_correlations(self, save_path=None):
        """Plot correlation matrix of sensor data."""
        if self.df is None or self.df.empty:
            print("No data available for correlation analysis")
            return
        
        numeric_columns = ['temperature_c', 'humidity_pct', 'co2_ppm', 'light_lux', 'battery_v']
        available_columns = [col for col in numeric_columns if col in self.df.columns]
        
        if len(available_columns) < 2:
            print("Need at least 2 numeric columns for correlation analysis")
            return
        
        # Calculate correlation matrix
        corr_matrix = self.df[available_columns].corr()
        
        # Create heatmap
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
                   square=True, fmt='.2f', cbar_kws={'shrink': 0.8})
        plt.title('Sensor Data Correlation Matrix')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Correlation plot saved to: {save_path}")
        else:
            plt.show()
    
    def plot_distributions(self, save_path=None):
        """Plot distribution of sensor values."""
        if self.df is None or self.df.empty:
            print("No data available for distribution analysis")
            return
        
        numeric_columns = ['temperature_c', 'humidity_pct', 'co2_ppm', 'light_lux', 'battery_v']
        available_columns = [col for col in numeric_columns if col in self.df.columns]
        
        if not available_columns:
            print("No numeric sensor data available for distribution analysis")
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        axes = axes.flatten()
        
        for i, column in enumerate(available_columns[:6]):
            if i < len(axes):
                self.df[column].hist(bins=30, ax=axes[i], alpha=0.7, edgecolor='black')
                axes[i].set_title(f'{column.replace("_", " ").title()} Distribution')
                axes[i].set_xlabel(self.get_unit(column))
                axes[i].set_ylabel('Frequency')
                axes[i].grid(True, alpha=0.3)
        
        # Hide unused subplots
        for i in range(len(available_columns), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        plt.suptitle('Sensor Data Distributions', y=1.02, fontsize=16)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Distribution plot saved to: {save_path}")
        else:
            plt.show()
    
    def detect_anomalies(self, threshold=2.5):
        """Detect anomalies in sensor data using statistical methods."""
        if self.df is None or self.df.empty:
            print("No data available for anomaly detection")
            return
        
        numeric_columns = ['temperature_c', 'humidity_pct', 'co2_ppm', 'light_lux', 'battery_v']
        available_columns = [col for col in numeric_columns if col in self.df.columns]
        
        print("\n" + "="*60)
        print("ANOMALY DETECTION")
        print("="*60)
        
        anomalies = {}
        
        for column in available_columns:
            # Calculate z-scores
            mean_val = self.df[column].mean()
            std_val = self.df[column].std()
            z_scores = np.abs((self.df[column] - mean_val) / std_val)
            
            # Find anomalies
            anomaly_mask = z_scores > threshold
            anomaly_count = anomaly_mask.sum()
            
            if anomaly_count > 0:
                anomalies[column] = {
                    'count': anomaly_count,
                    'percentage': (anomaly_count / len(self.df)) * 100,
                    'values': self.df[anomaly_mask][['timestamp', 'device_id', column]]
                }
                
                print(f"\n{column.replace('_', ' ').title()}:")
                print(f"  Anomalies found: {anomaly_count} ({anomalies[column]['percentage']:.2f}%)")
                print(f"  Threshold (z-score): {threshold}")
                
                # Show worst anomalies
                worst_anomalies = anomalies[column]['values'].nlargest(3, column)
                if not worst_anomalies.empty:
                    print("  Worst anomalies:")
                    for _, row in worst_anomalies.iterrows():
                        print(f"    {row['timestamp']}: {row[column]} (Device: {row['device_id'][:8]}...)")
        
        if not anomalies:
            print("No anomalies detected with the current threshold.")
        
        return anomalies
    
    def get_unit(self, column):
        """Get the unit for a sensor column."""
        units = {
            'temperature_c': '°C',
            'humidity_pct': '%',
            'co2_ppm': 'ppm',
            'light_lux': 'lux',
            'battery_v': 'V'
        }
        return units.get(column, '')
    
    def generate_report(self, output_dir='analysis_output'):
        """Generate a comprehensive analysis report."""
        if self.df is None or self.df.empty:
            print("No data available for report generation")
            return
        
        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        print(f"\nGenerating analysis report in: {output_path}")
        
        # Generate plots
        self.plot_time_series(output_path / 'time_series.png')
        plt.close('all')
        
        self.plot_correlations(output_path / 'correlations.png')
        plt.close('all')
        
        self.plot_distributions(output_path / 'distributions.png')
        plt.close('all')
        
        # Generate text report
        report_file = output_path / 'analysis_report.txt'
        with open(report_file, 'w') as f:
            f.write("TELEMETRY DATA ANALYSIS REPORT\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Generated: {datetime.now()}\n\n")
            
            # Redirect stdout to capture statistics
            import io
            from contextlib import redirect_stdout
            
            with redirect_stdout(io.StringIO()) as output:
                self.basic_statistics()
                self.detect_anomalies()
            
            f.write(output.getvalue())
        
        print(f"Analysis report saved to: {report_file}")
        print(f"Plots saved in: {output_path}")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Analyze IoT telemetry data')
    parser.add_argument('--data', '-d', help='Path to telemetry data file (JSON lines format)')
    parser.add_argument('--output', '-o', default='analysis_output',
                       help='Output directory for analysis results')
    parser.add_argument('--stats-only', action='store_true',
                       help='Only show basic statistics, no plots')
    parser.add_argument('--sample-data', action='store_true',
                       help='Use generated sample data for demonstration')
    
    args = parser.parse_args()
    
    # Setup logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        # Create analyzer
        analyzer = TelemetryAnalyzer(args.data if not args.sample_data else None)
        
        # Load data
        analyzer.load_data()
        
        if args.stats_only:
            # Only show statistics
            analyzer.basic_statistics()
            analyzer.detect_anomalies()
        else:
            # Generate full report
            analyzer.generate_report(args.output)
    
    except Exception as e:
        print(f"Error during analysis: {e}")
        return 1
    
    return 0


if __name__ == '__main__':
    sys.exit(main())